# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iaFCeGHcvNjqZ-FBPNazoSE_jB3RkGKG
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from google.colab import drive

# Google Drive'ı bağlama
drive.mount('/content/drive')

# Veriyi yükleme fonksiyonu
def load_data(file_path):
    data = np.load(file_path)
    return data

# Dosya yolları
data_file_path = '/content/drive/MyDrive/birlesik_sayisal_veri.npy'
model_save_path = '/content/drive/MyDrive/final_model.keras'
best_model_save_path = '/content/drive/MyDrive/best_model.keras'

# Veriyi yükle
data = load_data(data_file_path)

# Verideki indekslerin sınır aşımı kontrolü
vocab_size = 304216

# İndekslerin kontrolü ve düzeltme
if np.any(data >= vocab_size):
    print("Veride sınır aşan indeksler var.")
    out_of_bounds_indices = np.where(data >= vocab_size)
    print(f"Sınır aşan indekslerin yerleri: {out_of_bounds_indices}")
    data[out_of_bounds_indices] = vocab_size - 1
    print("Sınır aşan indeksler düzeltildi.")
else:
    print("Veride sınır aşan indeks yok.")

# Veriyi giriş ve hedeflere ayırma fonksiyonu
def split_data(data, split_ratio=0.8):
    split_index = int(len(data) * split_ratio)
    X = data[:, :-1]  # Son eleman hariç
    y = data[:, -1]   # Son eleman
    X_train = X[:split_index]
    y_train = y[:split_index]
    X_val = X[split_index:]
    y_val = y[split_index:]
    return X_train, y_train, X_val, y_val

X_train, y_train, X_val, y_val = split_data(data)

# Modeli tanımlama
embedding_dim = 256
rnn_units = 64

model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=X_train.shape[1]),
    LSTM(rnn_units, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dropout(0.3),
    Dense(vocab_size, activation='softmax')
])

# Modelin özetini yazdırarak katmanları kontrol edin
model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Callback'ler
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint(best_model_save_path, monitor='val_loss', save_best_only=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)

# Eğitim
epochs = 2
batch_size = 256

for epoch in range(epochs):
    print(f'Epoch {epoch + 1}/{epochs}')

    history = model.fit(
        X_train,
        y_train,
        epochs=1,
        batch_size=batch_size,
        validation_data=(X_val, y_val),
        callbacks=[early_stopping, model_checkpoint, reduce_lr],
        verbose=1
    )

    # Her epoch sonunda eğitim ve doğrulama kaybını ve doğruluğunu yazdır
    train_loss = history.history['loss'][0]
    train_accuracy = history.history['accuracy'][0]
    val_loss = history.history['val_loss'][0]
    val_accuracy = history.history['val_accuracy'][0]

    print(f'Epoch {epoch + 1}/{epochs}')
    print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}')
    print(f'Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}')

# Modelin son halini kaydet
model.save(model_save_path)
print("Model eğitim tamamlandı ve kaydedildi.")

# Modeli yükleme
loaded_model = tf.keras.models.load_model(model_save_path)

# Tahminler yapma
y_pred_proba = loaded_model.predict(X_val)
y_pred = np.argmax(y_pred_proba, axis=1)

# Metrikleri hesaplama
accuracy = accuracy_score(y_val, y_pred)
precision = precision_score(y_val, y_pred, average='weighted')
recall = recall_score(y_val, y_pred, average='weighted')
f1 = f1_score(y_val, y_pred, average='weighted')

print("Test Sonuçları:")
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')